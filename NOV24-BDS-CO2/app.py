import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from PIL import Image
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.neighbors import NearestNeighbors

# Chargement du dataset
data_path = "/Users/bouchaibchelaoui/Desktop/DATASCIENTEST/PROJET_CO2_DST/src_new/data"
csv_file = os.path.join(data_path, "DF2023-22-21_Concat_Finale_2.csv")
df = pd.read_csv(csv_file)
df.columns = df.columns.str.strip()  # Nettoyage des noms de colonnes

target = "Ewltp (g/km)"


images_path = "/Users/bouchaibchelaoui/Desktop/DATASCIENTEST/PROJET_CO2_DST/src_new/images"


# Mod√®les sans marques (baseline)
path = "/Users/bouchaibchelaoui/Desktop/DATASCIENTEST/PROJET_CO2_DST/src_new/models"
# Mod√®les sans marques (baseline)
pipeline_rf_sm = joblib.load(os.path.join(path, "pipeline_random_forest_sm.pkl"))
pipeline_lr_sm = joblib.load(os.path.join(path, "pipeline_linear_regression_sm.pkl"))
pipeline_knn_sm = joblib.load(os.path.join(path, "pipeline_knn_sm.pkl"))
pipeline_rf_tpot_sm = joblib.load(os.path.join(path, "pipeline_random_forest_opt_tpot_sm.pkl"))

# Mod√®les avec marques (√©tendus)
pipeline_rf_ext = joblib.load(os.path.join(path, "pipeline_random_forest_opt_tpot.pkl"))
pipeline_lr_ext = joblib.load(os.path.join(path, "pipeline_linear_regression_ext.pkl"))
pipeline_knn_ext = joblib.load(os.path.join(path, "pipeline_knn_ext.pkl"))
extended_features = joblib.load(os.path.join(data_path, "features_rf_opt_tpot.pkl"))

baseline_features = ["m (kg)", "ec (cm3)", "ep (KW)", "Erwltp (g/km)", "Fuel consumption", "Ft_Diesel", "Ft_Essence"]


brand_columns = [
    'Mk_ALFA ROMEO', 'Mk_ALLIED VEHICLES', 'Mk_ALPINE', 'Mk_AUDI', 'Mk_BENTLEY', 'Mk_BMW',
    'Mk_CITROEN', 'Mk_CUPRA', 'Mk_DACIA', 'Mk_FIAT', 'Mk_FORD', 'Mk_HONDA', 'Mk_HYUNDAI',
    'Mk_JAGUAR', 'Mk_JEEP', 'Mk_KIA', 'Mk_LAMBORGHINI', 'Mk_LANCIA', 'Mk_LAND ROVER',
    'Mk_LEXUS', 'Mk_MASERATI', 'Mk_MAZDA', 'Mk_MERCEDES', 'Mk_MINI', 'Mk_MITSUBISHI',
    'Mk_NISSAN', 'Mk_OPEL', 'Mk_PEUGEOT', 'Mk_PORSCHE', 'Mk_RENAULT', 'Mk_SEAT',
    'Mk_SKODA', 'Mk_SUBARU', 'Mk_SUZUKI', 'Mk_TOYOTA', 'Mk_VOLKSWAGEN', 'Mk_VOLVO',
    'Mk_MAN', 'Mk_NILSSON'
]

extended_features = baseline_features + brand_columns


@st.cache_data(show_spinner=False)
def compute_comparison_metrics(df, baseline_features, extended_features,
                               _pipeline_rf_sm, _pipeline_lr_sm, _pipeline_knn_sm, _pipeline_rf_tpot_sm,
                               _pipeline_rf_ext, _pipeline_lr_ext, _pipeline_knn_ext):
    y_true = df["Ewltp (g/km)"]
    
    # Calcul pour les mod√®les sans marques (baseline)
    baseline_models = {
        "Random Forest": _pipeline_rf_sm,
        "Random Forest optimis√©": _pipeline_rf_tpot_sm,
        "R√©gression Lin√©aire": _pipeline_lr_sm,
        "KNN": _pipeline_knn_sm
    }
    mse_baseline = {}
    r2_baseline = {}
    X_base = df[baseline_features]
    for name, model in baseline_models.items():
        y_pred = model.predict(X_base)
        mse_baseline[name] = mean_squared_error(y_true, y_pred)
        r2_baseline[name] = r2_score(y_true, y_pred)
    
    # Calcul pour les mod√®les avec marques (√©tendus)
    extended_models = {
        "Random Forest": _pipeline_rf_ext,
        "Random Forest optimis√©": _pipeline_rf_ext,
        "R√©gression Lin√©aire": _pipeline_lr_ext,
        "KNN": _pipeline_knn_ext
    }
    mse_extended = {}
    r2_extended = {}
    X_ext = df[extended_features]
    for name, model in extended_models.items():
        y_pred = model.predict(X_ext)
        mse_extended[name] = mean_squared_error(y_true, y_pred)
        r2_extended[name] = r2_score(y_true, y_pred)
    
    data = []
    for model_name in ["Random Forest", "Random Forest optimis√©", "R√©gression Lin√©aire", "KNN"]:
        data.append({
            "Mod√®le": model_name,
            "MSE (Sans Marques)": mse_baseline[model_name],
            "R¬≤ (Sans Marques)": r2_baseline[model_name],
            "MSE (Avec Marques)": mse_extended[model_name],
            "R¬≤ (Avec Marques)": r2_extended[model_name]
        })
    return pd.DataFrame(data)



st.markdown(
    """
    <style>
    [data-testid="stSidebar"] > div:first-child {
        background-color: #BBAE98; 
        color: white;  
    }
    </style>
    """,
    unsafe_allow_html=True
)


st.title("Projet CO2 DATASCIENTEST")
st.sidebar.title("Sommaire")
pages = [
    "Pr√©sentation du Projet",
    "Pre-processing",
    "DataVizualization",
    "Mod√©lisation sans marques",
    "Mod√©lisation avec marques",
    "Comparaison des mod√®les"
]

page = st.sidebar.radio("Aller vers", pages)

###############################################
# Page 1 : Pr√©sentation du Projet
###############################################

if page == pages[0]:
    st.write("# Pr√©diction des √âmissions de CO‚ÇÇ")

    voitureco2_path = os.path.join(images_path, "voitureco2.png")
    image = Image.open(voitureco2_path)
    st.image(image, use_container_width=True)  
        
    st.write("## Contexte du Projet")
    st.write(
        """
        Face aux enjeux climatiques et aux r√©gulations strictes sur les √©missions de CO‚ÇÇ, il devient essentiel de mieux comprendre 
        et pr√©dire l'empreinte carbone des v√©hicules en circulation.  
        Ce projet vise √† **d√©velopper un mod√®le de Machine Learning permettant de pr√©dire les √©missions de CO‚ÇÇ (Ewltp)**
        en fonction des caract√©ristiques techniques et de la consommation des v√©hicules.
        """
    )
    
    st.write("## Objectifs du Projet")
    st.write(
        """
        - **Analyser** les facteurs influen√ßant les √©missions de CO‚ÇÇ.
        - **Explorer et visualiser** les relations entre les caract√©ristiques des v√©hicules et leurs √©missions.
        - **D√©velopper un mod√®le de pr√©diction performant** bas√© sur l‚Äôapprentissage supervis√©.
        - **Accompagner les d√©cisions √©cologiques** des consommateurs et des constructeurs.
        """
    )
    
    st.write("## Donn√©es Utilis√©es")
    st.write(
        """
        Ce projet s‚Äôappuie sur les donn√©es officielles de l‚Äô**Agence Europ√©enne pour l‚ÄôEnvironnement (EEA)**, issues des bases de donn√©es **2021, 2022 et 2023**.
        L‚Äôobjectif de cette fusion est d‚Äôenrichir le dataset et d‚Äôam√©liorer la pr√©cision du mod√®le en int√©grant un maximum de v√©hicules.
        
        üîó [Acc√©der au dataset de 2023](https://www.eea.europa.eu/en/datahub/datahubitem-view/fa8b1229-3db6-495d-b18e-9c9b3267c02b)  
        üîó [Acc√©der au dataset de 2022](https://www.eea.europa.eu/en/datahub/datahubitem-view/fa8b1229-3db6-495d-b18e-9c9b3267c02b?activeAccordion=1094576%2C1091011)  
        üîó [Acc√©der au dataset de 2021](https://www.eea.europa.eu/en/datahub/datahubitem-view/fa8b1229-3db6-495d-b18e-9c9b3267c02b?activeAccordion=1094576%2C1091011%2C1086949)
        """
    )
    
    st.write("### Variables Cl√©s du Dataset")
    st.write(
        """
        Le dataset comprend plusieurs caract√©ristiques essentielles des v√©hicules, notamment :
        - **Masse du v√©hicule** (`m (kg)`)
        - **Type de carburant** (`Ft`)
        - **Cylindr√©e du moteur** (`ec (cm3)`)
        - **Puissance du moteur** (`ep (KW)`)
        - **Consommation de carburant** (`Fuel consumption`)
        - **R√©duction d‚Äô√©missions WLTP** (`Erwltp (g/km)`)
        - **√âmissions de CO‚ÇÇ WLTP** (`Ewltp (g/km)`) ‚Äì **Variable cible**
        """
    )
    
    st.write("## Qu'est-ce que la Norme WLTP ?")
    st.write(
        """
        La **norme WLTP (Worldwide Harmonized Light Vehicles Test Procedure)** est un protocole de test permettant de mesurer de mani√®re plus pr√©cise :
        - La **consommation de carburant** des v√©hicules.
        - Les **√©missions de CO‚ÇÇ** dans des conditions proches de la r√©alit√©.
        
        Avant **2018**, l‚Äôancienne norme **NEDC** √©tait utilis√©e, mais elle ne refl√©tait pas les conditions de conduite r√©elles.  
        Le **WLTP** apporte plusieurs am√©liorations :
        - Des **tests plus longs et r√©alistes**.
        - Une meilleure prise en compte de **l‚Äôimpact des √©quipements**.
        - Une **meilleure pr√©cision des valeurs d‚Äô√©missions**.
        """
    )
    
    st.write("## M√©thodologie du Projet")
    st.write(
        """
        **1. Pr√©-traitement des Donn√©es (Pre-processing)**  
        - Nettoyage et transformation.
        - Gestion des valeurs manquantes et des outliers.
        - Normalisation des variables.
        
        **2. Analyse Exploratoire et Visualisation**  
        - √âtude des corr√©lations.
        - Visualisation des distributions.
        
        **3. Mod√©lisation et Comparaison**  
        - Test de plusieurs algorithmes.
        - Optimisation via GridSearchCV.
        
        **4. D√©ploiement avec Streamlit**  
        - Interface interactive pour la pr√©diction.
        """
    )
    
    st.write(
        """
        ---  
        **Explorez les √©tapes du projet via le menu lat√©ral !**
        """
    )

###############################################
# Page 2 : Pr√©-processing des Donn√©es
###############################################


# pre processing a expliquer ici

if page == pages[1]:
    st.write("## Pr√©-processing des Donn√©es")
    st.write("### 1Ô∏è‚É£ Pr√©sentation des donn√©es")
    st.write("Initialement, le jeu de donn√©es est constitu√© de 3 datasets (ann√©es 2021, 2022 et 2023) pour un total d'environ 30 millions de lignes et 40 colonnes.")
    st.write("Rappel: Les datasets sont t√©l√©chargeables √† cette adresse : https://www.eea.europa.eu/data-and-maps/data/co2-cars-emission-20")



    # Df pour afficher manuellement la structure des colonnes

    data_info = pd.DataFrame([
        {"Nom de la colonne": "ID", "Description": "Num√©ro d'identification de l'observation", "Type": "int64", "Remarque": "Pas utile pour la construction du mod√®le"},
        {"Nom de la colonne": "Country", "Description": "Pays de provenance du v√©hicule", "Type": "object", "Remarque": "Variable indicative - Pas utile pour la construction du mod√®le"},
        {"Nom de la colonne": "VFN", "Description": "Num√©ro d'identification de la famille de v√©hicule", "Type": "object", "Remarque": "Variable indicative - Pas utile pour la construction du mod√®le"},
        {"Nom de la colonne": "Mp", "Description": "Rassemblements de constructeurs", "Type": "object", "Remarque": "Variable indicative - Pas utile pour la construction du mod√®le"},
        {"Nom de la colonne": "Mh", "Description": "Nom du constructeur selon la d√©nomination standard de l'UE", "Type": "object", "Remarque": "Doublon avec 'Mp'"},
        {"Nom de la colonne": "Man", "Description": "Nom du constructeur selon la d√©claration du fabricant d'origine", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "MMS", "Description": "Nom du constructeur selon la d√©nomination du registre des √âtats membres", "Type": "float64", "Remarque": "A supprimer"},
        {"Nom de la colonne": "Tan", "Description": "Num√©ro d'homologation de type", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "T", "Description": "Type", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Va", "Description": "Variant", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Ve", "Description": "Version", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Mk", "Description": "Fabriquant / Marque du v√©hicule", "Type": "object", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Cn", "Description": "Nom commercial", "Type": "object", "Remarque": "Non utilis√© pour l'entra√Ænement du mod√®le mais √† la comparaison et l'identification des valeurs aberrantes"},
        {"Nom de la colonne": "Ct", "Description": "Cat√©gorie du type de v√©hicule homologu√©", "Type": "object", "Remarque": "Pas de l√©gende = Inutilisable"},
        {"Nom de la colonne": "Cr", "Description": "Cat√©gorie du v√©hicule immatricul√©", "Type": "object", "Remarque": "Doublon avec 'Ct'"},
        {"Nom de la colonne": "r", "Description": "Total des nouvelles immatriculations", "Type": "int64", "Remarque": "Une seule modalit√© : 1 sur toutes les lignes"},
        {"Nom de la colonne": "M (kg)", "Description": "Masse en ordre de marche pour un v√©hicule enti√®rement assembl√©", "Type": "float64", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Mt", "Description": "Masse d'essai selon la proc√©dure WLTP", "Type": "float64", "Remarque": "Doublon avec 'M (kg)'"},
        {"Nom de la colonne": "Enedc (g/km)", "Description": "√âmissions sp√©cifiques de CO2 (NEDC)", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "Ewltp (g/km)", "Description": "√âmissions sp√©cifiques de CO2 (WLTP)", "Type": "float64", "Remarque": "Variable cible"},
        {"Nom de la colonne": "W (mm)", "Description": "Empattement (distance entre les centre des roues avant et arri√®re d'un v√©hicule)", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "At1 (mm)", "Description": "Largeur de l'essieu de direction", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "At2 (mm)", "Description": "Largeur de l'essieu autre que celui de direction", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "Ft", "Description": "Type de carburant", "Type": "object", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Fm", "Description": "Mode de carburant", "Type": "object", "Remarque": "Doublon avec Ft"},
        {"Nom de la colonne": "Ec (cm3)", "Description": "Cylindr√©e du moteur", "Type": "float64", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Ep (KW)", "Description": "Puissance du moteur", "Type": "float64", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Z (Wh/km)", "Description": "Consommation d'√©nergie √©lectrique", "Type": "float64", "Remarque": "Variable r√©serv√©e aux v√©hicules √©lectriques et hybrides rechargeables"},
        {"Nom de la colonne": "IT", "Description": "Technologie innovante ou groupe de technologies innovantes", "Type": "object", "Remarque": "Pas de l√©gende = Inutilisable"},
        {"Nom de la colonne": "Ernedc (g/km)", "Description": "R√©duction des √©missions gr√¢ce √† des technologies innovantes", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "Erwltp (g/km)", "Description": "R√©duction des √©missions gr√¢ce √† des technologies innovantes (WLTP)", "Type": "float64", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "De", "Description": "Facteur de d√©viation", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "Vf", "Description": "Facteur de v√©rification", "Type": "float64", "Remarque": "Colonne uniquement compos√©e de valeurs manquantes"},
        {"Nom de la colonne": "Year", "Description": "Ann√©e de d√©claration (et de constitution du dataset)", "Type": "int64", "Remarque": "Conserver √† titre indicatif pour la fusion des diff√©rents datasets"},
        {"Nom de la colonne": "Status", "Description": "Statut des donn√©es (P = Donn√©es provisoires, F = Donn√©es finales)", "Type": "object", "Remarque": "Toutes les donn√©es sont marqu√©es comme provisoires"},
        {"Nom de la colonne": "Date of registration", "Description": "Date d'immatriculation", "Type": "object", "Remarque": "Peu d'int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "Fuel consumption", "Description": "Consommation de carburant", "Type": "float64", "Remarque": "Int√©r√™t pour la suite de l'analyse"},
        {"Nom de la colonne": "ech", "Description": "Normes d'√©missions europ√©ennes", "Type": "object", "Remarque": "Cat√©gories √† normaliser car les donn√©es se recoupent sous diff√©rentes d√©nominations + Beaucoup de NaN = Finalement supprim√©e"},
        {"Nom de la colonne": "RLFI", "Description": "R√©f√©rence d'homologation", "Type": "object", "Remarque": "Pas de l√©gende = Inutilisable"},
        {"Nom de la colonne": "Electric range (km)", "Description": "Autonomie √©lectrique (km)", "Type": "float64", "Remarque": "Uniquement pour les v√©hicules √©lectriques et hybrides rechargeables"},
        ])


    st.write("### Structure du Dataset üìä")
    st.dataframe(data_info, hide_index=True)

    st.write("### 2Ô∏è‚É£ S√©lection des variables pour le mod√®le") 
    st.write("Le dataset initial contient 40 colonnes mais une grande partie d‚Äôentre elles ont √©t√© supprim√©es pour des raisons de pertinence (ex : caract√©ristiques esth√©tiques du v√©hicule ou identifiants uniques) et de qualit√© des donn√©es (taux de nan trop √©lev√©).")
    columns_to_keep = ['Mk', 'M (kg)', 'Ewltp (g/km)', 'Ft', 'Ec (cm3)', 'Ep (KW)','Z (Wh/km)', 'Erwltp (g/km)', 'Fuel consumption', 'Electric range (km)']
    st.write("Apr√®s une premi√®re s√©lection, voici une liste de colonnes potentiellement pertinentes pour la pr√©diction des √©missions de CO‚ÇÇ :")
    st.write(columns_to_keep)

    st.write("#### Modification de la variable 'Ft'")
    st.write("la colonne 'Ft' (type de carburant) contient une dizaine de modalit√©. Les v√©hicules ont √©t√© r√©group√© selon 4 classes de la mani√®re suivante :")
    dico_ft1 = {'petrol': 'Essence',
             'hydrogen' : 'Essence',
             'e85': 'Essence',
             'lpg': 'Essence',
             'ng': 'Essence',
             'ng-biomethane' : 'Essence',
             'diesel': 'Diesel',
             'petrol/electric': 'Hybride',
             'diesel/electric': 'Hybride',
             'electric' : 'Electrique'}
    st.write(dico_ft1)

    # repartition des types de carburant
    st.write("#### R√©partition des types de Carburant")
    fuel_counts = {
        "Diesel": 44,
        "Electrique": 1.5,
        "Essence": 54,
        "Hybride": 0.5
    }

    # graph des carburants
    fig, ax = plt.subplots()
    ax.pie(fuel_counts.values(), labels=fuel_counts.keys(), autopct="%1.1f%%", 
           colors=["gold", "red", "green", "lightblue"], startangle=90)
    st.pyplot(fig)



    st.write("Dans ce dataset, les v√©hicules √©lectriques ne produisent pas de CO‚ÇÇ. Les v√©hicules √©lectriques ont donc √©t√© √©cart√©s")
    st.write("Concernant les v√©hicules hybrides, plus de la moiti√© des observations non pas la colonne 'Ewltp (g/km)' (√©mission de CO‚ÇÇ) de renseign√©e. Avec un nombre aussi limit√© d‚Äôobservations valides, conserver cette cat√©gorie introduirait un biais important et ne permettrait pas une analyse math√©matiquement rigoureuse. Ainsi, par souci de fiabilit√© et de repr√©sentativit√© des donn√©es, cette classe a √©t√© √©cart√©e.")
    
    st.write("#### Suppression des colonnes 'Z (Wh/km)' et 'Electric range (km)'")
    st.write("Ces deux colonnes repr√©sentent respectivement la consommation d'√©nergie √©lectrique et l'autonomie √©lectrique en km. Ces variables sont sp√©cifiques aux v√©hicules √©lectriques et hybrides. Par cons√©quences elles sont aussi suprimm√©es.")


    st.write("### 3Ô∏è‚É£ Traitement pour les marques des v√©hicules")
    st.write("Nous avons inclus la possibilit√© de s√©lectionner un certains nombres de marques pour √©valuer l‚Äôeffet potentiel du constructeur sur la production de CO‚ÇÇ")
    st.write("Cela a n√©cessit√© un travail important de standardisation, les noms des marques dans le dataset n'√©taient pas uniformis√©s. Certaines √©taient √©crites en majuscules, d‚Äôautres en minuscules. Il existait plusieurs variantes pour une m√™me marque")
    st.write("De nombreuses mentions peuvent √™tre rassembl√©es sous une seule d√©nomination afin de r√©duire leur nombre. Par exemple, ‚ÄòMercedes‚Äô, ‚ÄòMercedes-Benz‚Äô et ‚ÄòMercedes Benz‚Äô peuvent √™tre regroup√©s sous ‚ÄòMercedes‚Äô uniquement.")
    st.write("Voici un aper√ßu des marques les plus repr√©sent√©es dans le dataset")

    countplot_path = os.path.join(images_path, "Countplot_Mk.png")
    image_marque = Image.open(countplot_path)
    st.image(image_marque, use_container_width=True)

    st.write("### 4Ô∏è‚É£ Suppression des doublons et valeurs manquantes")
    st.write("Bien que les datasets originaux soient extr√™mement denses (pr√®s de 10 millions d‚Äôentr√©es chacuns), en regardant les doublons de plus pr√®s, nous pouvons constater qu‚Äôils sont extr√™mement nombreux (98% pour chaque jeu de donn√©es !).")
    st.write("En effet, ces datasets regroupent les d√©clarations des pays europ√©ens concernant les nouvelles immatriculations de v√©hicules sur leur territoire en 2021, 2022 et 2023.") 
    st.write("Les √©missions de CO2 √©tant les m√™mes pour chaque mod√®le de v√©hicule. Par exemple, 200 000 Audi A1 ont √©t√© immatricul√©es en 2023 sur l‚Äôensemble de l‚ÄôUnion Europ√©enne, nous avons donc 1 ligne et 199 999 doublons potentiels sur cette ann√©e sp√©cifique. Il est donc n√©cessaire de supprimer les doublons, ce qui diminue grandement la taille du dataset.")
    st.write("Enfin les lignes pr√©sentant au moins une valeurs manquantes ont √©t√© supprim√©es.")


    st.write("### 5Ô∏è‚É£ D√©tection des Outliers")
    st.write("Pour d√©tecter et supprimer les outliers, nous avons proc√©d√© par diff√©rentes √©tapes. D‚Äôabord, nous avons regroup√© les v√©hicules pr√©sents dans le jeu de donn√©es selon leur mod√®le, leur type de carburant et leur ann√©e (ex. : T-ROC Essence de 2023). ")
    st.write("Ensuite, √† l‚Äôaide d‚Äôune fonction d‚Äôagr√©gation, nous avons calcul√© individuellement la moyenne des colonnes num√©riques pour chacune de ces cat√©gories. Nous avons ajout√© cette nouvelle variable √† notre jeu de donn√©es original, avant de calculer, pour chaque colonne et pour chaque ligne, la diff√©rence entre la valeur r√©elle et la moyenne correspondante, que nous avons stock√©e dans une deuxi√®me variable.")
    st.write("Enfin, nous avons calcul√© l‚Äô√©cart interquartile de la distribution de ces diff√©rences et d√©termin√© un seuil √† ne pas d√©passer. Ce seuil est ensuite utilis√© pour identifier les valeurs jug√©es aberrantes.")
    st.write("Gr√¢ce √† la d√©finition d‚Äôune fonction et √† l‚Äôutilisation d‚Äôune boucle for, nous sommes d√©sormais capables d‚Äôimpl√©menter cette strat√©gie pour toutes les colonnes num√©riques du jeu de donn√©es et de mettre de c√¥t√© les outliers au fur et √† mesure. Cela r√©duit la taille du jeu de donn√©es final, mais garantit des r√©sultats fiables lors des pr√©dictions, car le mod√®le n‚Äôest plus perturb√© par ces valeurs aberrantes.")
    st.write("Voici un exemple graphique de la sortie de notre fonction, associ√©e √† une boucle for :")

    im_outlier = os.path.join(images_path, "Exemple_Detect_Outliers.png")
    image_marque = Image.open(im_outlier)
    st.image(image_marque, use_container_width=True)

    st.write("### 6Ô∏è‚É£ Concat√©nation des datasets")
    st.write("Afin d‚Äôenrichir un maximum le jeu de donn√©es sans alt√©rer les r√©sultats, le dataset initial (2023) est complet√© avec celui des ann√©es pr√©cedentes (2022 et 2021).")
    st.write("Apr√®s une observation approfondie des diff√©rentes colonnes et de leur remplissage, nous avons constat√© que seules les deux ann√©es pr√©c√©dentes √©taient enti√®rement compatibles avec notre processus de pr√©traitement et notre mod√©lisation (2021 et 2022). Au-del√†, nous nous exposions √† des soucis de coh√©rence (beaucoup de valeurs manquantes dans certaines de nos colonnes et des disparit√©s de variables avant 2016).")
    st.write("Nous avons charg√© s√©par√©ment les datasets et appliqu√© les m√™mes √©tapes de preprocessing que pour celui de 2023. Nous avons proc√©d√© ainsi car une concat√©nation en tout d√©but de traitement aurait √©t√© beaucoup trop lourde et compliqu√©e √† g√©rer (cela aurait cr√©√© un dataset de pr√®s de 30 millions de lignes au total).")

    st.write("### 7Ô∏è‚É£ Encodage et aper√ßu du dataset")
    st.write("Une fois le dataset final assembl√©, les variables cat√©gorielles 'Ft' et 'Mk' sont encod√©es (one-hot encoding).")
    st.write("Le dataset est pr√™t √† l'emploi pour entra√Æner le mod√®le.")
    st.write(df.head())

###############################################
# Page 3 : Data Visualization
###############################################
elif page == pages[2]:
    st.write("## Data Visualization")
    st.write("### Analyse Exploratoire des Donn√©es")
    
    dico_mapping = {
        "Masse du v√©hicule (kg)": "m (kg)",
        "Cylindr√©e (cm¬≥)": "ec (cm3)",
        "Puissance (kW)": "ep (KW)",
        "R√©duction d‚Äô√©missions WLTP (g/km)": "Erwltp (g/km)",
        "Consommation de carburant (L/100km)": "Fuel consumption",
        "√âmissions de CO‚ÇÇ (g/km)": "Ewltp (g/km)"
    }
    col_display_names = list(dico_mapping.keys())
    
    st.write("### Heatmap des Corr√©lations")
    true_col_names = list(dico_mapping.values())
    df_corr = df[true_col_names].corr()
    dico_inverser = {v: k for k, v in dico_mapping.items()}
    df_corr = df_corr.rename(index=dico_inverser, columns=dico_inverser)
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.heatmap(df_corr, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5, ax=ax)
    plt.xticks(rotation=45)
    st.pyplot(fig)
    
    st.write("### Distribution des variables")
    col_relation_selected_display_1 = st.selectbox("S√©lectionner une variable num√©rique :", col_display_names, key=1)
    col_relation_selected_1 = dico_mapping[col_relation_selected_display_1]
    fig, ax = plt.subplots(figsize=(8, 5))
    sns.histplot(df[col_relation_selected_1], bins=30, kde=True, color="blue", ax=ax)
    ax.set_xlabel(col_relation_selected_display_1)
    ax.set_ylabel("Nombre de V√©hicules")
    ax.set_title(f"Distribution de {col_relation_selected_display_1}")
    st.pyplot(fig)
    
    st.write("### D√©tection des Outliers via Boxplots")
    cols_boxplot = ["Ewltp (g/km)", "ec (cm3)", "ep (KW)", "Fuel consumption"]
    fig, axes = plt.subplots(1, len(cols_boxplot), figsize=(18, 6))
    for i, col in enumerate(cols_boxplot):
        sns.boxplot(y=df[col], ax=axes[i], color="cyan")
        axes[i].set_title(f"Boxplot de {col}")
    st.pyplot(fig)
    
    st.write("### Relation entre une variable et les √©missions de CO‚ÇÇ")
    col_relation_selected_display_2 = st.selectbox("S√©lectionner une variable num√©rique :", col_display_names, key=2)
    col_relation_selected_2 = dico_mapping[col_relation_selected_display_2]
    fig, ax = plt.subplots(figsize=(8, 5))
    sns.scatterplot(x=df[col_relation_selected_2], y=df["Ewltp (g/km)"], alpha=0.5, color="red", ax=ax)
    ax.set_xlabel(col_relation_selected_display_2)
    ax.set_ylabel("√âmissions de CO‚ÇÇ (g/km)")
    ax.set_title(f"Relation entre {col_relation_selected_display_2} et √âmissions de CO‚ÇÇ")
    st.pyplot(fig)
    
    st.write("### R√©partition des types de Carburant")
    fuel_counts = {
        "Diesel": df["Ft_Diesel"].sum(),
        "Essence": df["Ft_Essence"].sum()
    }
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.pie(fuel_counts.values(), labels=fuel_counts.keys(), autopct="%1.1f%%", 
           colors=["gold", "lightblue", "green"], startangle=90)
    ax.set_title("R√©partition par Type de Carburant")
    st.pyplot(fig)


###############################################
# Page 4 : Mod√©lisation sans marques (Baseline)
###############################################

elif page == "Mod√©lisation sans marques":
    st.write("## Mod√©lisation sans marques")
    model_choice = st.selectbox("Choisissez un mod√®le", 
                                ["Random Forest", "Random Forest optimis√©", "R√©gression Lin√©aire", "KNN"])
    
    with st.form("prediction_form_baseline"):
        st.write("### Entrez les valeurs du v√©hicule pour pr√©dire les √©missions de CO‚ÇÇ (sans marques)")
        col1, col2 = st.columns(2)
        with col1:
            m_kg = st.number_input("Masse du v√©hicule (kg)", min_value=500, max_value=3000, step=1)
            ec_cm3 = st.number_input("Cylindr√©e (cm¬≥)", min_value=500, max_value=6000, step=1)
        with col2:
            ep_kw = st.number_input("Puissance (kW)", min_value=20, max_value=500, step=1)
            erwltp = st.number_input("R√©duction d‚Äô√©missions WLTP (g/km)", min_value=0.0, max_value=3.5, step=0.01)
        fuel_consumption = st.number_input("Consommation de carburant (L/100km)", min_value=2.0, max_value=15.0, step=0.1)
        ft = st.selectbox("Type de carburant", ["Diesel", "Essence"])
        fuel_types = {"Diesel": [1, 0], "Essence": [0, 1]}
        ft_encoded = fuel_types[ft]
        
        # Construction de l'input de base (7 valeurs)
        input_values = [m_kg, ec_cm3, ep_kw, erwltp, fuel_consumption] + ft_encoded
        input_data_df = pd.DataFrame([input_values], columns=baseline_features)
        
        submitted = st.form_submit_button("üîé Pr√©dire")
        if submitted:
            if model_choice == "Random Forest":
                prediction = pipeline_rf_sm.predict(input_data_df)
                
                # Extraction et affichage de l'importance des features
                rf_model = pipeline_rf_sm.named_steps["rf"]
                importances_stacking = rf_model.feature_importances_
                feature_names_stacking = list(baseline_features)
                importances_df_stacking = pd.DataFrame({
                    'Feature': feature_names_stacking,
                    'Importance': importances_stacking 
                }).sort_values(by='Importance', ascending=False)
                
                fig, ax = plt.subplots()
                ax.barh(importances_df_stacking["Feature"], importances_df_stacking["Importance"])
                ax.set_xlabel("Importance")
                ax.set_ylabel("Features")
                ax.set_title("Feature Importance - Random Forest")
                ax.invert_yaxis()  # Le plus important en haut
                st.pyplot(fig)
            
            elif model_choice == "Random Forest optimis√©":
                nb_brands = len(brand_columns)
                extended_input = input_values + [0] * nb_brands
                input_data_extended = pd.DataFrame([extended_input], columns=extended_features)
                prediction = pipeline_rf_ext.predict(input_data_extended)

                rf_model_tpot = pipeline_rf_tpot_sm.named_steps["rf"]
                importances_stacking_tpot = rf_model_tpot.feature_importances_
                feature_names_stacking = list(baseline_features)
                importances_df_stacking_tpot = pd.DataFrame({
                    'Feature': feature_names_stacking,
                    'Importance': importances_stacking_tpot 
                }).sort_values(by='Importance', ascending=False)

                fig, ax = plt.subplots()
                ax.barh(importances_df_stacking_tpot["Feature"], importances_df_stacking_tpot["Importance"])
                ax.set_xlabel("Importance")
                ax.set_ylabel("Features")
                ax.set_title("Feature Importance - RandomForest optimis√© (TPOT)")
                ax.invert_yaxis()
                st.pyplot(fig)

            elif model_choice == "R√©gression Lin√©aire":
                prediction = pipeline_lr_sm.predict(input_data_df)
                
                lr_model = pipeline_lr_sm.named_steps["lr"]
                coefs = lr_model.coef_
                df_coefs = pd.DataFrame({"Feature": baseline_features, "Coefficient": coefs})
                df_coefs = df_coefs.sort_values(by="Coefficient", ascending=False)
                
                fig, ax = plt.subplots()
                ax.barh(df_coefs["Feature"], df_coefs["Coefficient"])
                ax.set_xlabel("Coefficient Value")
                ax.set_ylabel("Features")
                ax.set_title("Feature Coefficients - Linear Regression")
                ax.invert_yaxis()
                st.pyplot(fig)
                
            elif model_choice == "KNN":
                prediction = pipeline_knn_sm.predict(input_data_df)
                
                # Charger les valeurs SHAP pour le mod√®le KNN
                data_path = "/Users/bouchaibchelaoui/Desktop/DATASCIENTEST/PROJET_CO2_DST/src_new/data"
                shap_file = os.path.join(data_path, "shap_values_knn.pkl")
                shap_values = joblib.load(shap_file)
                
                df_shap = pd.DataFrame({
                    "Feature": list(baseline_features), 
                    "Importance": np.abs(shap_values).mean(axis=0)
                }).sort_values(by="Importance", ascending=False)
                
                fig, ax = plt.subplots()
                ax.barh(df_shap["Feature"], df_shap["Importance"])
                ax.set_xlabel("Valeur SHAP")
                ax.set_ylabel("Features")
                ax.set_title("Feature Importance - KNN")
                ax.invert_yaxis()
                st.pyplot(fig)
            
            st.success(f"üìä Estimation (sans marques) : **{prediction[0]:.2f} g/km**")

###############################################
# Page 5 : Mod√©lisation avec marques (√âtendu)
###############################################
elif page == "Mod√©lisation avec marques":
    st.write("## Mod√©lisation avec marques")
    model_choice = st.selectbox("Choisissez un mod√®le", 
                                ["Random Forest", "Random Forest optimis√©", "R√©gression Lin√©aire", "KNN"],
                                key="ext_model")
    
    with st.form("prediction_form_extended"):
        st.write("### Entrez les valeurs du v√©hicule pour pr√©dire les √©missions de CO‚ÇÇ (avec marques)")
        col1, col2 = st.columns(2)
        with col1:
            m_kg = st.number_input("Masse du v√©hicule (kg)", min_value=500, max_value=3000, step=1, key="ext_m_kg")
            ec_cm3 = st.number_input("Cylindr√©e (cm¬≥)", min_value=500, max_value=8000, step=1, key="ext_ec_cm3")
            ep_kw = st.number_input("Puissance (kW)", min_value=20, max_value=500, step=1, key="ext_ep_kw")
        with col2:
            erwltp = st.number_input("R√©duction d‚Äô√©missions WLTP (g/km)", min_value=0.0, max_value=5.0, step=0.01, key="ext_erwltp")
            fuel_consumption = st.number_input("Consommation de carburant (L/100km)", min_value=2.0, max_value=30.0, step=0.1, key="ext_fuel_consumption")
            ft = st.selectbox("Type de carburant", ["Diesel", "Essence"], key="ext_ft")
        # Comme les hybrides ont √©t√© supprim√©s, nous utilisons seulement Diesel et Essence.
        fuel_types = {"Diesel": [1, 0], "Essence": [0, 1]}
        ft_encoded = fuel_types[ft]
        
        # S√©lection de la marque (bien que nous ne filtrons pas sur la marque pour la comparaison globale)
        selected_brand = st.selectbox("S√©lectionnez la marque du v√©hicule", brand_columns, key="ext_brand")
        brand_values = [1 if col == selected_brand else 0 for col in brand_columns]
        
        # Construction de l'input complet pour le mod√®le √©tendu :
        # Baseline (7 valeurs) + fuel encoding (2 valeurs) + marque (len(brand_columns))
        extended_input = [m_kg, ec_cm3, ep_kw, erwltp, fuel_consumption] + ft_encoded + brand_values
        input_data_df = pd.DataFrame([extended_input], columns=extended_features)
        
        submitted = st.form_submit_button("üîé Pr√©dire")
        if submitted:
            if model_choice == "Random Forest":
                prediction = pipeline_rf_ext.predict(input_data_df)
            elif model_choice == "Random Forest optimis√©":
                prediction = pipeline_rf_ext.predict(input_data_df)
            elif model_choice == "R√©gression Lin√©aire":
                prediction = pipeline_lr_ext.predict(input_data_df)
            elif model_choice == "KNN":
                prediction = pipeline_knn_ext.predict(input_data_df)
            st.success(f"üìä Estimation (avec marques) : **{prediction[0]:.2f} g/km**")

            # Liste des noms de colonnes utilis√©es pour l'entra√Ænement du mod√®le NN
            features_for_nn = ["m (kg)", "ec (cm3)", "ep (KW)", "Fuel consumption", "Erwltp (g/km)"]

            # Cr√©er un DataFrame pour input_vector au lieu d'un tableau NumPy
            input_vector = pd.DataFrame([[m_kg, ec_cm3, ep_kw, fuel_consumption, erwltp]], 
                                        columns=features_for_nn)

            # Utilisation de input_vector avec le mod√®le NN
            nn_model = NearestNeighbors(n_neighbors=1).fit(df[features_for_nn])
            distances, indices = nn_model.kneighbors(input_vector)

            # R√©cup√©ration de l'indice du v√©hicule le plus similaire
            closest_index = indices[0][0]

            # Valeur r√©elle associ√©e √† ce v√©hicule
            point_reel = df[target].iloc[closest_index]

            # 2) Pr√©parez la distribution globale
            actual_values = np.sort(df[target].dropna().values)

            # 3) Cr√©ation du graphique
            fig, ax = plt.subplots(figsize=(8,6))

            # Scatterplot de la distribution globale (valeurs tri√©es)
            ax.scatter(range(len(actual_values)), actual_values, color="blue", alpha=0.6, label="Valeurs r√©elles (tri√©es)")

            # On identifie o√π se situe le point_reel dans le tableau tri√©
            # M√©thode : on cherche l‚Äôindex d‚Äôinsertion de point_reel dans actual_values
            pos_point = np.searchsorted(actual_values, point_reel)

            # On affiche un marqueur vert pour la valeur r√©elle du v√©hicule similaire
            ax.scatter(pos_point, point_reel, color="green", s=100, zorder=5, label="Valeur r√©elle (v√©hicule similaire)")

            # Ligne horizontale rouge pour la valeur pr√©dite
            ax.axhline(y=prediction[0], color="red", linestyle="--", linewidth=2, label="Valeur pr√©dite")

            # Ajustements divers
            ax.set_xlabel("Index (valeurs tri√©es)")
            ax.set_ylabel("√âmissions de CO‚ÇÇ (g/km)")
            ax.set_title("Distribution des valeurs r√©elles vs Valeur pr√©dite")
            ax.legend()

            st.pyplot(fig)


###############################################
# Page 6 : Comparaison des mod√®les (tableau et graphique)
###############################################

elif page == "Comparaison des mod√®les":
    st.write("## Comparaison des performances des mod√®les")
    
    df_comparison = compute_comparison_metrics(
        df, baseline_features, extended_features,
        pipeline_rf_sm, pipeline_lr_sm, pipeline_knn_sm, pipeline_rf_tpot_sm,
        pipeline_rf_ext, pipeline_lr_ext, pipeline_knn_ext
    )
    
    st.write("### R√©sultats de l'√©valuation des mod√®les")
    st.table(df_comparison)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    x = np.arange(len(df_comparison))
    width = 0.35
    
    ax1.bar(x - width/2, df_comparison["MSE (Sans Marques)"], width, label="Sans Marques")
    ax1.bar(x + width/2, df_comparison["MSE (Avec Marques)"], width, label="Avec Marques")
    ax1.set_xticks(x)
    ax1.set_xticklabels(df_comparison["Mod√®le"], rotation=45)
    ax1.set_ylabel("MSE")
    ax1.set_title("Comparaison des MSE")
    ax1.legend()
    
    ax2.bar(x - width/2, df_comparison["R¬≤ (Sans Marques)"], width, label="Sans Marques")
    ax2.bar(x + width/2, df_comparison["R¬≤ (Avec Marques)"], width, label="Avec Marques")
    ax2.set_xticks(x)
    ax2.set_xticklabels(df_comparison["Mod√®le"], rotation=45)
    ax2.set_ylabel("R¬≤")
    ax2.set_title("Comparaison des R¬≤")
    ax2.legend()
    
    st.pyplot(fig)
    
    st.markdown("""
    ### **üìå Analyse des r√©sultats**
    - **Random Forest optimis√© (TPOT)** donne les meilleurs r√©sultats avec une **faible MSE** et un **score R¬≤ proche de 1**.
    - **La R√©gression Lin√©aire** pr√©sente une **MSE √©lev√©e**, indiquant qu'elle n'est pas adapt√©e √† ce probl√®me.
    - **Le mod√®le KNN** fonctionne correctement mais est moins performant que les m√©thodes bas√©es sur Random Forest.
    - **Le mod√®le Random Forest de base** reste int√©ressant, mais l'optimisation par TPOT am√©liore ses performances.
    
    üí° **Conclusion :** Le mod√®le **Random Forest optimis√© avec TPOT** semble √™tre le plus performant. üöÄ
    """)

